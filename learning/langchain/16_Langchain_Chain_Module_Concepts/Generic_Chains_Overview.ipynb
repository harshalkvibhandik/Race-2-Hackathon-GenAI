{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "336b9395",
   "metadata": {},
   "source": [
    "# Generic Chains Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcb42ef",
   "metadata": {},
   "source": [
    "## Simple Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b094e82",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "The most elementary type of chain is known as a basic chain, which represents the simplest form of crafting a chain. <br>In this setup, there is only one Language Model (LLM) responsible for receiving an input prompt and using it for generating text.\n",
    "<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43b5cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please install the package as per your requirement :)\n",
    "#!pip install openai==1.5.0\n",
    "#!pip install langchain==0.0.351\n",
    "#!pip install huggingface-hub==0.19.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b36c04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d7c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5547ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "436017aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"place\"],\n",
    "    template=\"Best places to visit in {place}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2477a555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Agra – Home to the iconic Taj Mahal, Agra is one of the most popular tourist destinations in India.\n",
      "\n",
      "2. Jaipur – Also known as the “Pink City”, Jaipur is a great place to experience the culture and heritage of Rajasthan.\n",
      "\n",
      "3. Goa – One of India’s most famous beach destinations, Goa offers plenty of sun, sand and sea.\n",
      "\n",
      "4. Udaipur – Also known as the “City of Lakes”, Udaipur is a great place to explore Rajasthan’s forts and palaces.\n",
      "\n",
      "5. Kerala – Located in the South, Kerala is popular for its beautiful backwaters, abundant wildlife and lush greenery.\n",
      "\n",
      "6. Andaman and Nicobar Islands – A paradise for beach lovers, the Andaman and Nicobar Islands offer plenty of opportunities for adventure and relaxation.\n",
      "\n",
      "7. Varanasi – Situated on the banks of the Ganges, Varanasi is a city steeped in culture and spirituality.\n",
      "\n",
      "8. Shimla – Situated in the foothills of the Himalayas, Shimla is a great place to escape the\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain only specifying the input variable.\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88205e2",
   "metadata": {},
   "source": [
    "## Simple Sequential Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb1850c",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "Sequential Chains involves making a series of consecutive calls to the language model.<br> This approach proves especially valuable when there is a need to utilize the output generated from one call as the input for another call.\n",
    "<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76654563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92f94dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You have to suggest 5 best places to visit in {place}?\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"place\"], \n",
    "    template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77104326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "HF_llm= HuggingFaceHub(repo_id = \"google/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2578b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa350baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4ea5942",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Given a list a places, please estimate the expenses to visit all of them in local currency and also the days needed\n",
    "{expenses}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"expenses\"],\n",
    "    template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61ca518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef315099",
   "metadata": {},
   "outputs": [],
   "source": [
    "expenses_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16e97f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = SimpleSequentialChain(chains=[place_chain, expenses_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98487cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m1. Taj Mahal, Agra\n",
      "2. Golden Temple, Amritsar\n",
      "3. Goa\n",
      "4. Jaipur\n",
      "5. Kerala Backwaters\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "The estimated expenses to visit all the places in local currency would be approximately Rs. 40,000. This includes travel costs, accommodation, and food. The number of days needed to visit all the places would be around 7-8 days.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "review = final_chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c09bca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
